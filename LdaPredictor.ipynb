{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sych_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk; nltk.download('stopwords')\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.append('привет')\n",
    "russian_stopwords.append('спасибо')\n",
    "russian_stopwords.append('пожалуйста')\n",
    "russian_stopwords.append('пока')\n",
    "russian_stopwords.append('добрый')\n",
    "russian_stopwords.append('день')\n",
    "russian_stopwords.append('nan')\n",
    "russian_stopwords.append('end')\n",
    "russian_stopwords.append('утро')\n",
    "russian_stopwords.append('ок')\n",
    "russian_stopwords.append('здравствуйте')\n",
    "russian_stopwords.append('мочь')\n",
    "russian_stopwords.append('не')\n",
    "russian_stopwords.append('работать')\n",
    "russian_stopwords.append('сей')\n",
    "russian_stopwords.append('пора')\n",
    "russian_stopwords.append('очень')\n",
    "russian_stopwords.append('проблема')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LdaPredictor():\n",
    "    \n",
    "    def __init__(self, lda_path, dict_path, bigram_path, trigram_path):\n",
    "        \"\"\"\n",
    "        lda_path - путь к lda модели\n",
    "        dict_path - путь к словарю \n",
    "        bigram_path - путь к биграммам\n",
    "        trigram_path - путь к триграммам\n",
    "        \n",
    "        param: lda_path str\n",
    "        param: dict_path str\n",
    "        param: bigram_path str\n",
    "        param: trigram_path str\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(dict_path)\n",
    "        self.lda = LdaMulticore.load(lda_path)\n",
    "        self.bigram_path = bigram_path\n",
    "        self.trigram_path = trigram_path\n",
    "        \n",
    "    def to_lemmatize2(self, text):\n",
    "        all_word_str = \" \".join(text)\n",
    "        all_word_list = all_word_str.split()\n",
    "        all_unique_word = Series(all_word_list).unique()\n",
    "        lemmatized_word_dict = {}\n",
    "        lemmatizer = MorphAnalyzer()\n",
    "        for word in all_unique_word:\n",
    "            lemmatized_word_dict[word] = lemmatizer.normal_forms(word)[0]\n",
    "        text = ' '.join([lemmatized_word_dict[word] for word in text])\n",
    "        return text, all_unique_word\n",
    "        \n",
    "    def clean(self, text):\n",
    "        deleted_symols = '[\\\\\\\\\\'[\\]!\"$%&()*+,-./:;<=>?@^_`{|}~«»\\n]'\n",
    "        text = re.sub(deleted_symols, ' ', text)\n",
    "        \n",
    "        text = ' '.join([elem for elem in str(text).split(' ') if elem.isdigit() == False])\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = [token for token in text.split() if token not in russian_stopwords]\n",
    "        #text = [token for token in text if token]\n",
    "        text, _ = self.to_lemmatize2(text)\n",
    "        \n",
    "        return ' '.join(text)\n",
    "    \n",
    "    def bigram(self, text):\n",
    "        bigram = Phrases.load(self.bigram_path)\n",
    "        trigram = Phrases.load(self.trigram_path)\n",
    "        text_clean = text\n",
    "        for idx in range(len(text_clean)):\n",
    "            for token in bigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "            for token in trigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "        return text_clean\n",
    "    \n",
    "    def predict(self, text):\n",
    "        clean_text = self.clean(text).split()\n",
    "        print(clean_text)\n",
    "        bigram = self.bigram([clean_text])\n",
    "        new_review_bow = self.dictionary.doc2bow(bigram[0])\n",
    "        new_review_lda = self.lda[new_review_bow]\n",
    "        return sorted(new_review_lda, reverse=True, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = \"./model/best_model.lda\"\n",
    "dict_path = \"./model/dictionary.dict\"\n",
    "bigram_path = \"./model/bigram.phs\"\n",
    "trigram_path = \"./model/trigram.phs\"\n",
    "lda = LdaPredictor(lda_path, dict_path,  bigram_path, trigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  '0.032*\"поставщик\" + 0.016*\"просить_помочь\" + 0.015*\"подтверждение\" + 0.012*\"ооо\" + 0.012*\"документ\" + 0.011*\"сделать\" + 0.010*\"видеть\" + 0.009*\"нужно\" + 0.008*\"перемещение\" + 0.008*\"1с\"'),\n",
       " (2,\n",
       "  '0.019*\"касса\" + 0.010*\"эник\" + 0.009*\"пз\" + 0.009*\"год\" + 0.008*\"договор\" + 0.008*\"аналитик\" + 0.008*\"магазин\" + 0.007*\"ок\" + 0.007*\"заполнить\" + 0.007*\"инна\"'),\n",
       " (6,\n",
       "  '0.036*\"удалённый\" + 0.036*\"рабочий_стол\" + 0.033*\"удалённый_доступ\" + 0.031*\"рабочий\" + 0.027*\"доступ\" + 0.027*\"подключиться\" + 0.023*\"компьютер\" + 0.023*\"стол\" + 0.020*\"зайти\" + 0.017*\"удалённый_рабочий\"'),\n",
       " (0,\n",
       "  '0.020*\"база\" + 0.015*\"висеть\" + 0.013*\"очень\" + 0.012*\"программа\" + 0.011*\"сервер\" + 0.010*\"перезагрузить\" + 0.010*\"зайти\" + 0.009*\"заработать\" + 0.009*\"долго\" + 0.008*\"минута\"'),\n",
       " (5,\n",
       "  '0.051*\"выдавать_ошибка\" + 0.030*\"выдавать\" + 0.020*\"фото_—\" + 0.015*\"ерп\" + 0.015*\"сервис_деск\" + 0.014*\"личный_кабинет\" + 0.011*\"фото\" + 0.010*\"ар00\" + 0.010*\"помочь\" + 0.010*\"вечер\"'),\n",
       " (1,\n",
       "  '0.023*\"принять\" + 0.015*\"всд\" + 0.012*\"документ\" + 0.011*\"поставщик\" + 0.009*\"поставить_приход\" + 0.009*\"доверительный_приёмка\" + 0.009*\"чат_бот\" + 0.008*\"номер\" + 0.008*\"ттн\" + 0.008*\"приход\"'),\n",
       " (11,\n",
       "  '0.016*\"цена\" + 0.012*\"ещё\" + 0.010*\"отчёт\" + 0.010*\"время\" + 0.010*\"документ\" + 0.009*\"ждать\" + 0.009*\"сделать\" + 0.008*\"данный_момент\" + 0.007*\"провести\" + 0.007*\"почему\"'),\n",
       " (3,\n",
       "  '0.043*\"пароль\" + 0.019*\"зайти\" + 0.019*\"учётный_запись\" + 0.012*\"войти\" + 0.011*\"запись\" + 0.011*\"учётный\" + 0.010*\"вводить\" + 0.009*\"получиться\" + 0.008*\"логин_пароль\" + 0.008*\"подключиться\"'),\n",
       " (9,\n",
       "  '0.026*\"ошибка_пко\" + 0.022*\"сервис\" + 0.016*\"качество_сервис\" + 0.015*\"пко\" + 0.015*\"работа\" + 0.013*\"качество\" + 0.012*\"обращение\" + 0.011*\"устроить_—\" + 0.011*\"ок\" + 0.011*\"font\"'),\n",
       " (7,\n",
       "  '0.020*\"позиция\" + 0.016*\"код\" + 0.014*\"рц\" + 0.012*\"задача\" + 0.012*\"гм\" + 0.011*\"цена\" + 0.010*\"поставщик\" + 0.010*\"1с\" + 0.009*\"цб_рц\" + 0.009*\"выгрузить\"')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['о', 'т', 'к', 'р', 'ы', 'т', 'и', 'е', 'ф', 'о', 'р', 'м', 'и', 'р', 'о', 'в', 'а', 'н', 'и', 'е', 'п', 'р', 'и', 'х', 'о', 'д', 'н', 'ы', 'й', 'н', 'а', 'к', 'л', 'а', 'д', 'н', 'ы', 'й', 'в', 'с', 'п', 'л', 'ы', 'в', 'а', 'т', 'ь', 'д', 'а', 'т', 'ь', 'о', 'ш', 'и', 'б', 'к', 'а', 'к', 'о', 'м', 'п', 'с', '9', 'м', 'о', 'ч', 'ь', 'п', 'о', 'с', 'т', 'а', 'в', 'и', 'т', 'ь', 'п', 'а', 'л', 'е', 'т', 'а', 'п', 'р', 'и', 'х', 'о', 'д']\n",
      "[(2, 0.34329468), (7, 0.123350665), (1, 0.104602076), (4, 0.05018462), (10, 0.049427148), (11, 0.049121812), (9, 0.048453752), (5, 0.047204766), (0, 0.046743352), (6, 0.046015613), (3, 0.045885153), (8, 0.045716353)]\n"
     ]
    }
   ],
   "source": [
    "text = \"При открытии формирования приходной накладной  всплывает данная ошибка. На всех компах С9  не можем поставить палеты на приход\"\n",
    "predict = lda.predict(text)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
