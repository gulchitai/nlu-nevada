{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sych_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk; nltk.download('stopwords')\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stopwords.csv', encoding = 'utf-8', sep=\";\")\n",
    "for index, row in df.iterrows():\n",
    "    russian_stopwords.append(row['stopword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LdaPredictor():\n",
    "    \n",
    "    def __init__(self, lda_path, dict_path, bigram_path, trigram_path):\n",
    "        \"\"\"\n",
    "        lda_path - путь к lda модели\n",
    "        dict_path - путь к словарю \n",
    "        bigram_path - путь к биграммам\n",
    "        trigram_path - путь к триграммам\n",
    "        \n",
    "        param: lda_path str\n",
    "        param: dict_path str\n",
    "        param: bigram_path str\n",
    "        param: trigram_path str\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(dict_path)\n",
    "        self.lda = LdaMulticore.load(lda_path)\n",
    "        self.bigram_path = bigram_path\n",
    "        self.trigram_path = trigram_path\n",
    "        \n",
    "    def to_lemmatize2(self, text):\n",
    "        all_word_str = \" \".join(text)\n",
    "        all_word_list = all_word_str.split()\n",
    "        all_unique_word = pd.Series(all_word_list).unique()\n",
    "        lemmatized_word_dict = {}\n",
    "        lemmatizer = MorphAnalyzer()\n",
    "        for word in all_unique_word:\n",
    "            lemmatized_word_dict[word] = lemmatizer.normal_forms(word)[0]\n",
    "        text = ' '.join([lemmatized_word_dict[word] for word in text])\n",
    "        return text, all_unique_word\n",
    "        \n",
    "    def clean(self, text):\n",
    "        deleted_symols = '[\\\\\\\\\\'[\\]!\"$%&()*+,-./:;<=>?@^_`{|}~«»\\n]'\n",
    "        text = re.sub(deleted_symols, ' ', text)\n",
    "        \n",
    "        text = ' '.join([elem for elem in str(text).split(' ') if elem.isdigit() == False])\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = [token for token in text.split() if token not in russian_stopwords]\n",
    "\n",
    "        text, _ = self.to_lemmatize2(text)\n",
    "        return text.split(' ')\n",
    "    \n",
    "    def bigram(self, text):\n",
    "        bigram = Phrases.load(self.bigram_path)\n",
    "        trigram = Phrases.load(self.trigram_path)\n",
    "        text_clean = text\n",
    "        for idx in range(len(text_clean)):\n",
    "            for token in bigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "            for token in trigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "        return text_clean\n",
    "    \n",
    "    def predict(self, text):\n",
    "        clean_text = self.clean(text)\n",
    "        bigram = self.bigram([clean_text])\n",
    "        new_review_bow = self.dictionary.doc2bow(bigram[0])\n",
    "        new_review_lda = self.lda[new_review_bow]\n",
    "        return sorted(new_review_lda, reverse=True, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = \"./model/best_model.lda\"\n",
    "dict_path = \"./model/dictionary.dict\"\n",
    "bigram_path = \"./model/bigram.phs\"\n",
    "trigram_path = \"./model/trigram.phs\"\n",
    "lda = LdaPredictor(lda_path, dict_path,  bigram_path, trigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.2751035), (9, 0.13903603), (4, 0.11002234), (6, 0.10841717), (3, 0.06604457), (2, 0.06021121), (11, 0.04744645), (10, 0.043350853), (1, 0.040084515), (7, 0.038676728), (0, 0.036911834), (8, 0.034694772)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.051*\"выдавать_ошибка\" + 0.030*\"выдавать\" + 0.020*\"фото_—\" + 0.015*\"ерп\" + 0.015*\"сервис_деск\" + 0.014*\"личный_кабинет\" + 0.011*\"фото\" + 0.010*\"ар00\" + 0.010*\"помочь\" + 0.010*\"вечер\" + 0.010*\"зайти\" + 0.009*\"ар00_ар00\" + 0.007*\"кабинет\" + 0.006*\"личный\" + 0.006*\"закрыть\" + 0.005*\"документ\" + 0.005*\"подключиться_удалёнка\" + 0.005*\"делать\" + 0.005*\"принтер\" + 0.005*\"ок\" + 0.005*\"просто\" + 0.005*\"деск\" + 0.005*\"программа\" + 0.005*\"сервис\" + 0.005*\"сэд\" + 0.004*\"вмс\" + 0.004*\"большой\" + 0.004*\"карточка_покупатель\" + 0.004*\"получиться\" + 0.004*\"печать\" + 0.004*\"вкладка\" + 0.004*\"написать\" + 0.004*\"самый\" + 0.004*\"портал\" + 0.004*\"закрывать\" + 0.004*\"кор_портал\" + 0.004*\"окно\" + 0.004*\"светлый\" + 0.004*\"1с\" + 0.004*\"заходить\" + 0.004*\"сделать\" + 0.003*\"заработать\" + 0.003*\"почта\" + 0.003*\"перезагрузка\" + 0.003*\"единый_сервис\" + 0.003*\"открываться\" + 0.003*\"решить\" + 0.003*\"нужно\" + 0.003*\"открыть\" + 0.003*\"печатать\"'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Здравствуйте. Нужна помощь по лкп. На телефон не могу дозвониться. Нужны права на управление мерчендайзерами. В личном кабинете вкладки мерчендайзер нет\"\n",
    "predict = lda.predict(text)\n",
    "print(predict)\n",
    "lda.lda.print_topic(predict[0][0], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
