{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sych_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk; nltk.download('stopwords')\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stopwords.csv', encoding = 'utf-8', sep=\";\")\n",
    "for index, row in df.iterrows():\n",
    "    russian_stopwords.append(row['stopword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LdaPredictor():\n",
    "    \n",
    "    def __init__(self, lda_path, dict_path, bigram_path, trigram_path):\n",
    "        \"\"\"\n",
    "        lda_path - путь к lda модели\n",
    "        dict_path - путь к словарю \n",
    "        bigram_path - путь к биграммам\n",
    "        trigram_path - путь к триграммам\n",
    "        \n",
    "        param: lda_path str\n",
    "        param: dict_path str\n",
    "        param: bigram_path str\n",
    "        param: trigram_path str\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(dict_path)\n",
    "        self.lda = LdaMulticore.load(lda_path)\n",
    "        self.bigram_path = bigram_path\n",
    "        self.trigram_path = trigram_path\n",
    "        \n",
    "    def to_lemmatize2(self, text):\n",
    "        all_word_str = \" \".join(text)\n",
    "        all_word_list = all_word_str.split()\n",
    "        all_unique_word = pd.Series(all_word_list).unique()\n",
    "        lemmatized_word_dict = {}\n",
    "        lemmatizer = MorphAnalyzer()\n",
    "        for word in all_unique_word:\n",
    "            lemmatized_word_dict[word] = lemmatizer.normal_forms(word)[0]\n",
    "        text = ' '.join([lemmatized_word_dict[word] for word in text])\n",
    "        return text, all_unique_word\n",
    "        \n",
    "    def clean(self, text):\n",
    "        deleted_symols = '[\\\\\\\\\\'[\\]!\"$%&()*+,-./:;<=>?@^_`{|}~«»\\n]'\n",
    "        text = re.sub(deleted_symols, ' ', text)\n",
    "        \n",
    "        text = ' '.join([elem for elem in str(text).split(' ') if elem.isdigit() == False])\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = [token for token in text.split() if token not in russian_stopwords]\n",
    "\n",
    "        text, _ = self.to_lemmatize2(text)\n",
    "        return text.split(' ')\n",
    "    \n",
    "    def bigram(self, text):\n",
    "        bigram = Phrases.load(self.bigram_path)\n",
    "        trigram = Phrases.load(self.trigram_path)\n",
    "        text_clean = text\n",
    "        for idx in range(len(text_clean)):\n",
    "            for token in bigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "            for token in trigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "        return text_clean\n",
    "    \n",
    "    def predict(self, text):\n",
    "        clean_text = self.clean(text)\n",
    "        bigram = self.bigram([clean_text])\n",
    "        new_review_bow = self.dictionary.doc2bow(bigram[0])\n",
    "        new_review_lda = self.lda[new_review_bow]\n",
    "        return sorted(new_review_lda, reverse=True, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = \"./model/best_model.lda\"\n",
    "dict_path = \"./model/dictionary.dict\"\n",
    "bigram_path = \"./model/bigram.phs\"\n",
    "trigram_path = \"./model/trigram.phs\"\n",
    "lda = LdaPredictor(lda_path, dict_path,  bigram_path, trigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.10157022), (5, 0.099726394), (9, 0.09570883), (1, 0.08199987), (4, 0.08175852), (6, 0.078894146), (3, 0.07884336), (7, 0.07805747), (2, 0.07728669), (11, 0.07597409), (10, 0.075552344), (8, 0.07462801)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.020*\"база\" + 0.015*\"висеть\" + 0.013*\"очень\" + 0.012*\"программа\" + 0.011*\"сервер\" + 0.010*\"перезагрузить\" + 0.010*\"зайти\" + 0.009*\"заработать\" + 0.009*\"долго\" + 0.008*\"минута\" + 0.008*\"весь_равно\" + 0.008*\"зависнуть\" + 0.008*\"почта\" + 0.008*\"терминал\" + 0.007*\"ничто_измениться\" + 0.007*\"ничто\" + 0.007*\"очень_долго\" + 0.007*\"ок\" + 0.006*\"открываться\" + 0.006*\"тест\" + 0.006*\"1с\" + 0.006*\"хороший\" + 0.006*\"перестать_работать\" + 0.006*\"рабочий_место\" + 0.005*\"dev\" + 0.005*\"зависать\" + 0.005*\"очень_медленно\" + 0.005*\"помочь\" + 0.005*\"упр\" + 0.005*\"вроде\" + 0.005*\"перезагружать\" + 0.005*\"запускаться\" + 0.005*\"перезагрузить_компьютер\" + 0.005*\"снова\" + 0.004*\"ещё\" + 0.004*\"очень_сильно\" + 0.004*\"компьютер\" + 0.004*\"вылетать\" + 0.004*\"измениться\" + 0.004*\"нормальный\" + 0.003*\"грузить\" + 0.003*\"стать\" + 0.003*\"место\" + 0.003*\"erp\" + 0.003*\"выкидывать\" + 0.003*\"чёрный_экран\" + 0.003*\"большой\" + 0.003*\"сильно\" + 0.003*\"перезагрузить_rc\" + 0.003*\"загружаться\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Добрый день. Ничего не работает, все сломалось!!! Помогите мне.\"\n",
    "predict = lda.predict(text)\n",
    "print(predict)\n",
    "lda.lda.print_topic(predict[0][0], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
