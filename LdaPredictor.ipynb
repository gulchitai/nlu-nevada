{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from operator import itemgetter\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sych_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk; nltk.download('stopwords')\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.append('привет')\n",
    "russian_stopwords.append('спасибо')\n",
    "russian_stopwords.append('пожалуйста')\n",
    "russian_stopwords.append('пока')\n",
    "russian_stopwords.append('добрый')\n",
    "russian_stopwords.append('день')\n",
    "russian_stopwords.append('nan')\n",
    "russian_stopwords.append('end')\n",
    "russian_stopwords.append('утро')\n",
    "russian_stopwords.append('ок')\n",
    "russian_stopwords.append('здравствуйте')\n",
    "russian_stopwords.append('мочь')\n",
    "russian_stopwords.append('не')\n",
    "russian_stopwords.append('работать')\n",
    "russian_stopwords.append('сей')\n",
    "russian_stopwords.append('пора')\n",
    "russian_stopwords.append('очень')\n",
    "russian_stopwords.append('проблема')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LdaPredictor():\n",
    "    \n",
    "    def __init__(self, lda_path, dict_path, bigram_path, trigram_path):\n",
    "        \"\"\"\n",
    "        lda_path - путь к lda модели\n",
    "        dict_path - путь к словарю \n",
    "        bigram_path - путь к биграммам\n",
    "        trigram_path - путь к триграммам\n",
    "        \n",
    "        param: lda_path str\n",
    "        param: dict_path str\n",
    "        param: bigram_path str\n",
    "        param: trigram_path str\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(dict_path)\n",
    "        self.lda = LdaMulticore.load(lda_path)\n",
    "        self.bigram_path = bigram_path\n",
    "        self.trigram_path = trigram_path\n",
    "        \n",
    "    def to_lemmatize2(self, text):\n",
    "        all_word_str = \" \".join(text)\n",
    "        all_word_list = all_word_str.split()\n",
    "        all_unique_word = Series(all_word_list).unique()\n",
    "        lemmatized_word_dict = {}\n",
    "        lemmatizer = MorphAnalyzer()\n",
    "        for word in all_unique_word:\n",
    "            lemmatized_word_dict[word] = lemmatizer.normal_forms(word)[0]\n",
    "        text = ' '.join([lemmatized_word_dict[word] for word in text])\n",
    "        return text, all_unique_word\n",
    "        \n",
    "    def clean(self, text):\n",
    "        deleted_symols = '[\\\\\\\\\\'[\\]!\"$%&()*+,-./:;<=>?@^_`{|}~«»\\n]'\n",
    "        text = re.sub(deleted_symols, ' ', text)\n",
    "        \n",
    "        text = ' '.join([elem for elem in str(text).split(' ') if elem.isdigit() == False])\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = [token for token in text.split() if token not in russian_stopwords]\n",
    "\n",
    "        text, _ = self.to_lemmatize2(text)\n",
    "        return text.split(' ')\n",
    "    \n",
    "    def bigram(self, text):\n",
    "        bigram = Phrases.load(self.bigram_path)\n",
    "        trigram = Phrases.load(self.trigram_path)\n",
    "        text_clean = text\n",
    "        for idx in range(len(text_clean)):\n",
    "            for token in bigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "            for token in trigram[text_clean[idx]]:\n",
    "                if '_' in token:\n",
    "                    text_clean[idx].append(token)\n",
    "        return text_clean\n",
    "    \n",
    "    def predict(self, text):\n",
    "        clean_text = self.clean(text)\n",
    "        bigram = self.bigram([clean_text])\n",
    "        new_review_bow = self.dictionary.doc2bow(bigram[0])\n",
    "        new_review_lda = self.lda[new_review_bow]\n",
    "        return sorted(new_review_lda, reverse=True, key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = \"./model/best_model.lda\"\n",
    "dict_path = \"./model/dictionary.dict\"\n",
    "bigram_path = \"./model/bigram.phs\"\n",
    "trigram_path = \"./model/trigram.phs\"\n",
    "lda = LdaPredictor(lda_path, dict_path,  bigram_path, trigram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.27512696), (9, 0.13909876), (4, 0.10990869), (6, 0.10839632), (3, 0.06605234), (2, 0.06023523), (11, 0.047455013), (10, 0.043355893), (1, 0.04008576), (7, 0.038678057), (0, 0.036912337), (8, 0.034694623)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.051*\"выдавать_ошибка\" + 0.030*\"выдавать\" + 0.020*\"фото_—\" + 0.015*\"ерп\" + 0.015*\"сервис_деск\" + 0.014*\"личный_кабинет\" + 0.011*\"фото\" + 0.010*\"ар00\" + 0.010*\"помочь\" + 0.010*\"вечер\"'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Здравствуйте. Нужна помощь по лкп. На телефон не могу дозвониться. Нужны права на управление мерчендайзерами. В личном кабинете вкладки мерчендайзер нет\"\n",
    "predict = lda.predict(text)\n",
    "print(predict)\n",
    "lda.lda.print_topic(predict[0][0], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
